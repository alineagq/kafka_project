# Kafka KRaft Cluster com S3 Sink & Monitoring

Este projeto cont√©m um cluster Kafka completo com KRaft (sem Zookeeper), Kafka Connect S3 Sink, LocalStack para testes S3 locais, e monitoramento via Prometheus.

## üèóÔ∏è Arquitetura

### Kafka Cluster
- **3 Controllers** (KRaft): Gerenciam metadados do cluster
  - controller1: porta 19093 (JMX: 19101)
  - controller2: porta 19094 (JMX: 19102)
  - controller3: porta 19095 (JMX: 19103)

- **3 Brokers**: Processam mensagens
  - broker1: porta 9092 (JMX: 9101)
  - broker2: porta 9093 (JMX: 9102)
  - broker3: porta 9094 (JMX: 9103)

### Kafka Connect & S3
- **Kafka Connect**: http://localhost:8083
  - S3 Sink Connector configurado
  - Streaming de t√≥picos para S3 (LocalStack)
  
- **LocalStack**: http://localhost:4566
  - Emulador AWS S3 local
  - Bucket: `kafka-events-bucket`
  - Sem custos AWS!

### Administra√ß√£o
- **AKHQ**: http://localhost:8080
  - ‚úÖ **Gerenciamento completo** - Topics, Consumers, Configs
  - ‚úÖ **Kafka Connect UI** - Gerenciar conectores visualmente
  - ‚úÖ **Monitoramento JMX** - M√©tricas de todos os brokers

### Monitoramento
- **Prometheus**: http://localhost:9090
- **JMX direto**: AKHQ acessa JMX diretamente, sem exporters extras!

## üöÄ Como Usar

### Guia Completo S3 Sink

üìñ **Veja o guia detalhado:** [S3-SINK-GUIDE.md](S3-SINK-GUIDE.md)

O guia completo inclui:
- Arquitetura do S3 Sink
- Como produzir mensagens de teste
- Como verificar arquivos no S3
- Gerenciamento de conectores
- Troubleshooting completo

### In√≠cio R√°pido

```bash
# 1. Subir toda a infraestrutura
podman-compose up -d

# 2. Aguardar servi√ßos iniciarem (30-60 segundos)
sleep 60

# 3. Criar t√≥pico 'events'
podman exec -it broker-1 kafka-topics --create \
    --bootstrap-server localhost:9092 \
    --topic events \
    --partitions 3 \
    --replication-factor 3

# 4. Criar conector S3 Sink
./s3-connector.sh create

# 5. Produzir mensagens de teste
podman exec -it broker-1 kafka-console-producer \
    --bootstrap-server localhost:9092 \
    --topic events

# Digite 3 mensagens JSON:
# {"id":1,"message":"test1"}
# {"id":2,"message":"test2"}
# {"id":3,"message":"test3"}
# Pressione Ctrl+C para sair

# 6. Verificar arquivos no S3 LocalStack
./s3-connector.sh show-s3
```

### Gerenciar Conector S3

```bash
# Ver status
./s3-connector.sh status

# Listar arquivos S3
./s3-connector.sh show-s3

# Reiniciar conector
./s3-connector.sh restart

# Deletar conector
./s3-connector.sh delete

# Ajuda
./s3-connector.sh help
```

### Comandos √öteis

#### Iniciar componentes espec√≠ficos
```bash
# Apenas Kafka (controllers + brokers)
podman-compose up -d controller1 controller2 controller3 broker1 broker2 broker3

# Kafka + Connect + LocalStack
podman-compose up -d controller1 controller2 controller3 broker1 broker2 broker3 kafka-connect localstack

# Apenas AKHQ
podman-compose up -d akhq

# Apenas Prometheus
podman-compose up -d prometheus
```

#### Verificar status
```bash
# Status de todos os servi√ßos
podman-compose ps

# Verificar sa√∫de do LocalStack
curl http://localhost:4566/_localstack/health

# Verificar Kafka Connect
curl http://localhost:8083/ | jq '.'
```

### Ver logs
```bash
# Logs de um servi√ßo espec√≠fico
podman-compose logs -f broker1
podman-compose logs -f kafka-connect
podman-compose logs -f localstack

# Logs de todos os brokers
podman-compose logs -f broker1 broker2 broker3
```

### Parar o ambiente
```bash
podman-compose down
```

### Parar e limpar volumes (dados ser√£o perdidos)
```bash
podman-compose down -v
```

## üìä M√©tricas no Prometheus

### M√©tricas Dispon√≠veis

#### Kafka Brokers/Controllers
- `kafka_server_*` - M√©tricas gerais do servidor Kafka
- `kafka_network_*` - M√©tricas de rede (requests, responses)
- `kafka_controller_*` - M√©tricas espec√≠ficas do controller
- `kafka_log_*` - M√©tricas de logs e segmentos
- `kafka_cluster_*` - M√©tricas do cluster (parti√ß√µes, replicas)

#### JVM
- `jvm_memory_*` - Uso de mem√≥ria heap e non-heap
- `jvm_gc_*` - Garbage collection
- `jvm_threads_*` - Threads da JVM

### Queries √öteis no Prometheus

Acesse http://localhost:9090 e experimente estas queries:

```promql
# Taxa de mensagens por segundo (entrada)
rate(kafka_server_brokertopicmetrics_messagesinpersec[1m])

# Taxa de bytes de entrada por broker
sum by (instance) (rate(kafka_server_brokertopicmetrics_bytesinpersec[1m]))

# Uso de mem√≥ria heap dos brokers
jvm_memory_heap_used / jvm_memory_heap_max * 100

# N√∫mero de parti√ß√µes under-replicated
kafka_server_replicamanager_underreplicatedpartitions

# Lat√™ncia de requisi√ß√µes de produce
kafka_network_requestmetrics_totaltimems{request="Produce"}

# N√∫mero de ISR (In-Sync Replicas) por parti√ß√£o
kafka_server_replicamanager_isrexpandspersec
```

## üîç Dashboards Grafana (opcional)

Para visualizar as m√©tricas graficamente, voc√™ pode adicionar o Grafana:

```yaml
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana-data:/var/lib/grafana
    depends_on:
      - prometheus
```

Depois:
1. Acesse http://localhost:3000 (admin/admin)
2. Adicione Prometheus como datasource (http://prometheus:9090)
3. Importe dashboards prontos:
   - Dashboard ID 721 (Kafka Overview)
   - Dashboard ID 7589 (Kafka Exporter Overview)

## üìù Configura√ß√µes Importantes

### JMX Configuration
Todos os brokers e controllers exp√µem m√©tricas JMX nas portas 9101.

### Prometheus Scrape Interval
As m√©tricas s√£o coletadas a cada 15 segundos (configur√°vel em `prometheus.yml`).

### Volumes Persistentes
Os dados s√£o armazenados em volumes Docker:
- `controller{1,2,3}-data`: Metadados dos controllers
- `broker{1,2,3}-data`: Dados das mensagens
- `prometheus-data`: M√©tricas hist√≥ricas
- `localstack-data`: Dados do S3 (bucket kafka-events-bucket)

## üìÅ Estrutura do Projeto

```
kafka-project/
‚îú‚îÄ‚îÄ docker-compose.yml              # Orquestra√ß√£o de todos os servi√ßos
‚îú‚îÄ‚îÄ prometheus.yml                  # Configura√ß√£o do Prometheus
‚îú‚îÄ‚îÄ jmx-exporter-config.yml        # Regras de m√©tricas JMX
‚îú‚îÄ‚îÄ s3-sink-connector.json         # Configura√ß√£o do S3 Sink Connector
‚îú‚îÄ‚îÄ s3-connector.sh                # Script de gerenciamento do conector
‚îú‚îÄ‚îÄ localstack-init/               # Scripts de inicializa√ß√£o LocalStack
‚îÇ   ‚îî‚îÄ‚îÄ 01-create-bucket.sh        # Cria bucket S3
‚îú‚îÄ‚îÄ S3-SINK-GUIDE.md              # Guia completo S3 Sink
‚îú‚îÄ‚îÄ METRICS-ARCHITECTURE.md        # Arquitetura de m√©tricas
‚îî‚îÄ‚îÄ README.md                      # Este arquivo
```

## üõ†Ô∏è Troubleshooting

### Kafka Connect

```bash
# Verificar se o plugin S3 est√° instalado
curl http://localhost:8083/connector-plugins | jq '.[] | select(.class | contains("S3"))'

# Ver logs do Kafka Connect
podman-compose logs -f kafka-connect

# Verificar status do conector
./s3-connector.sh status
```

### LocalStack S3

```bash
# Verificar sa√∫de do LocalStack
curl http://localhost:4566/_localstack/health

# Listar buckets
podman exec -it localstack awslocal s3 ls

# Recriar bucket manualmente
podman exec -it localstack awslocal s3 mb s3://kafka-events-bucket
```

### Arquivos N√£o Aparecem no S3

‚ö†Ô∏è **Lembre-se:** Arquivos s√≥ s√£o criados ap√≥s:
- **3 mensagens** (flush.size) OU
- **60 segundos** (rotate.interval.ms)

**Solu√ß√£o:** Envie 3 mensagens de teste para for√ßar flush.

### Brokers n√£o iniciam
```bash
# Verifique os logs
podman-compose logs broker1

# Verifique se os controllers est√£o rodando
podman-compose ps | grep controller
```

### Prometheus n√£o coleta m√©tricas
```bash
# Verifique os targets no Prometheus
# Acesse: http://localhost:9090/targets

# Teste conex√£o JMX manualmente
podman exec -it broker1 kafka-broker-api-versions --bootstrap-server localhost:9092
```

### JMX Exporter n√£o conecta
```bash
# Verifique se a porta JMX est√° acess√≠vel
podman exec -it broker1 nc -zv localhost 9101
```

## üìö Documenta√ß√£o

- **[S3-SINK-GUIDE.md](S3-SINK-GUIDE.md)** - Guia completo do S3 Sink Connector
- **[METRICS-ARCHITECTURE.md](METRICS-ARCHITECTURE.md)** - Arquitetura de m√©tricas
- [Kafka KRaft Documentation](https://kafka.apache.org/documentation/#kraft)
- [Confluent S3 Sink Connector](https://docs.confluent.io/kafka-connectors/s3-sink/current/overview.html)
- [LocalStack Documentation](https://docs.localstack.cloud/)
- [AKHQ Documentation](https://akhq.io/)
- [Prometheus JMX Exporter](https://github.com/prometheus/jmx_exporter)

## üéØ Features Implementadas

‚úÖ Kafka KRaft (3 controllers + 3 brokers)  
‚úÖ Kafka Connect com S3 Sink Connector  
‚úÖ LocalStack para testes S3 locais (sem AWS!)  
‚úÖ AKHQ - Interface completa de administra√ß√£o  
‚úÖ Prometheus - Monitoramento de m√©tricas  
‚úÖ JMX direto - Sem containers de exporter desnecess√°rios  
‚úÖ Scripts de gerenciamento (`s3-connector.sh`)  
‚úÖ Documenta√ß√£o completa em portugu√™s  

## üöÄ Pr√≥ximos Passos Sugeridos

1. **Adicionar Grafana** para dashboards visuais
2. **Configurar Alertmanager** para alertas de m√©tricas
3. **Adicionar Schema Registry** para valida√ß√£o Avro/Protobuf
4. **Implementar mais conectores** (JDBC, Elasticsearch, etc.)
5. **Configurar autentica√ß√£o** (SASL/SSL)
6. **Adicionar Kafka Streams** para processamento em tempo real

---

üí° **Dica:** Comece explorando o AKHQ em http://localhost:8080 para ter uma vis√£o visual completa do seu cluster!
